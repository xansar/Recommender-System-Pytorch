{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 加载依赖\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import CriteoDataset, CTRMetric, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.读取数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# 使用的超参数\n",
    "config = {\n",
    "    'TRAIN_BATCH_SIZE': 128,\n",
    "    'VALID_BATCH_SIZE': 128,\n",
    "    'TEST_BATCH_SIZE': 128,\n",
    "    'DEVICE': 'mps',\n",
    "    'NUM_WORKERS': 6,\n",
    "    'EPOCH': 30,\n",
    "    'NUM_FEATURE': 111,\n",
    "    'POS_WEIGHT': 2,\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'K': 8,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    }
   ],
   "source": [
    "# 使用的数据集为Criteo数据集\n",
    "train_pth = '../dataset/criteo-100k-train.txt'\n",
    "valid_pth = '../dataset/criteo-100k-valid.txt'\n",
    "test_pth = '../dataset/criteo-100k-test.txt'\n",
    "train_set = CriteoDataset(train_pth, mode='train')\n",
    "valid_set = CriteoDataset(valid_pth, mode='valid', encoders=train_set.encoders)\n",
    "test_set = CriteoDataset(valid_pth, mode='test', encoders=train_set.encoders)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=config['TRAIN_BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['NUM_WORKERS']\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_set,\n",
    "    batch_size=config['VALID_BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['NUM_WORKERS']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=config['TEST_BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['NUM_WORKERS']\n",
    ")\n",
    "\n",
    "# for e in range(2):\n",
    "#     for step, (batch_y, batch_X) in enumerate(tqdm(train_loader)):\n",
    "#         print(f'epoch: {e}\\tstep: {step}\\tbatch_X: {batch_X}\\tbatch_y: {batch_y}')\n",
    "#         if step >= 10:\n",
    "#             break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.模型构建与训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, num_features, k):\n",
    "        super(FM, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features)\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "\n",
    "        v = torch.zeros(num_features, k)\n",
    "        nn.init.xavier_uniform_(v)\n",
    "        self.V = nn.Parameter(v)\n",
    "\n",
    "\n",
    "    def forward(self, batch_x):\n",
    "        # batch_x: batch_size * num_features\n",
    "        batch_x = self.bn(batch_x)\n",
    "\n",
    "        linear_part = self.linear(batch_x) # batch_size * 1\n",
    "        # print(torch.mean(linear_part))\n",
    "        assert linear_part.shape == (batch_x.shape[0], 1)\n",
    "\n",
    "        cross_part_one = torch.pow(torch.matmul(batch_x, self.V), 2) # batch_size * k\n",
    "        cross_part_two = torch.matmul(torch.pow(batch_x, 2), torch.pow(self.V, 2)) # batch_size * k\n",
    "        cross_part = torch.sum(cross_part_one - cross_part_two, dim=1, keepdim=True) / 2\n",
    "        assert cross_part.shape == (batch_x.shape[0], 1)\n",
    "\n",
    "        output = linear_part + cross_part # batch_size * 1\n",
    "        assert output.shape == (batch_x.shape[0], 1)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Config==========\n",
      "TRAIN_BATCH_SIZE: 128\n",
      "VALID_BATCH_SIZE: 128\n",
      "TEST_BATCH_SIZE: 128\n",
      "DEVICE: mps\n",
      "NUM_WORKERS: 6\n",
      "EPOCH: 30\n",
      "NUM_FEATURE: 111\n",
      "POS_WEIGHT: 2\n",
      "LEARNING_RATE: 0.001\n",
      "K: 8\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "model = FM(num_features=config['NUM_FEATURE'], k=config['K'])\n",
    "weight = torch.tensor(config['POS_WEIGHT'])\n",
    "loss_func = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = optim.Adam(lr=config['LEARNING_RATE'], params=model.parameters())\n",
    "metric = CTRMetric()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer,\n",
    "    metric=metric,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    config=config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========TRAIN BEGIN==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:10<00:00, 60.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\n",
      "Loss: 0.7027184306144715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 1\n",
      "loss: 0.7920971671237221\n",
      "accuracy: 0.774624\n",
      "precision: 0.513410\n",
      "recall: 0.352539\n",
      "F1: 0.414027\n",
      "AUC: 0.743126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 62.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2\n",
      "Loss: 0.5497484426498414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 2\n",
      "loss: 0.7767308950424194\n",
      "accuracy: 0.778085\n",
      "precision: 0.523817\n",
      "recall: 0.351898\n",
      "F1: 0.417512\n",
      "AUC: 0.744747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 63.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3\n",
      "Loss: 0.5362244345188141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 3\n",
      "loss: 0.7733046850071678\n",
      "accuracy: 0.777097\n",
      "precision: 0.519133\n",
      "recall: 0.352676\n",
      "F1: 0.416079\n",
      "AUC: 0.745068\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 64.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4\n",
      "Loss: 0.5312279460906982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 4\n",
      "loss: 0.7623399639431434\n",
      "accuracy: 0.776998\n",
      "precision: 0.521343\n",
      "recall: 0.338911\n",
      "F1: 0.406921\n",
      "AUC: 0.743572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 64.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5\n",
      "Loss: 0.5293331715106964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 5\n",
      "loss: 0.7800632722770111\n",
      "accuracy: 0.778877\n",
      "precision: 0.524230\n",
      "recall: 0.364465\n",
      "F1: 0.426022\n",
      "AUC: 0.743983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 64.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6\n",
      "Loss: 0.5263361932277679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 6\n",
      "loss: 0.7773931222625926\n",
      "accuracy: 0.778184\n",
      "precision: 0.524660\n",
      "recall: 0.341787\n",
      "F1: 0.410011\n",
      "AUC: 0.740364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 63.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7\n",
      "Loss: 0.5261185575962066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 7\n",
      "loss: 0.7726753512515298\n",
      "accuracy: 0.773141\n",
      "precision: 0.504822\n",
      "recall: 0.354483\n",
      "F1: 0.413304\n",
      "AUC: 0.735912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 63.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8\n",
      "Loss: 0.5259076407909393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 8\n",
      "loss: 0.7769113077393061\n",
      "accuracy: 0.776899\n",
      "precision: 0.520084\n",
      "recall: 0.345021\n",
      "F1: 0.410702\n",
      "AUC: 0.741583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 64.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9\n",
      "Loss: 0.5255820212364197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 9\n",
      "loss: 0.7774409266966807\n",
      "accuracy: 0.776108\n",
      "precision: 0.518073\n",
      "recall: 0.350112\n",
      "F1: 0.413995\n",
      "AUC: 0.740809\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 63.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10\n",
      "Loss: 0.5242493866920471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 10\n",
      "loss: 0.7780119324032264\n",
      "accuracy: 0.778283\n",
      "precision: 0.523695\n",
      "recall: 0.352823\n",
      "F1: 0.417610\n",
      "AUC: 0.742124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 62.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11\n",
      "Loss: 0.5258041555881501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:03<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/xansar/PycharmProjects/RecommenderSystem/Recommender-System-Pytorch/MyImplement/utils/utils.py\", line 3, in <module>\n",
      "    import pandas_profiling as pp\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/__init__.py\", line 6, in <module>\n",
      "    from pandas_profiling.controller import pandas_decorator\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/controller/pandas_decorator.py\", line 4, in <module>\n",
      "    from pandas_profiling.profile_report import ProfileReport\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/profile_report.py\", line 14, in <module>\n",
      "    from pandas_profiling.expectations_report import ExpectationsReport\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/expectations_report.py\", line 9, in <module>\n",
      "    from pandas_profiling.utils.dataframe import slugify\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/utils/dataframe.py\", line 8, in <module>\n",
      "    import joblib\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/__init__.py\", line 120, in <module>\n",
      "    from .parallel import Parallel\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/parallel.py\", line 26, in <module>\n",
      "    from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 17, in <module>\n",
      "    from .pool import MemmappingPool\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/pool.py\", line 31, in <module>\n",
      "    from ._memmapping_reducer import get_memmapping_reducers\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/_memmapping_reducer.py\", line 37, in <module>\n",
      "    from .externals.loky.backend import resource_tracker\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/externals/loky/__init__.py\", line 11, in <module>\n",
      "    from .backend.context import cpu_count\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/externals/loky/backend/__init__.py\", line 13, in <module>\n",
      "    from multiprocessing import synchronize\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 971, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 640, in _compile_bytecode\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [69]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtest()\n",
      "File \u001B[0;32m~/PycharmProjects/RecommenderSystem/Recommender-System-Pytorch/MyImplement/utils/utils.py:427\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    425\u001B[0m all_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric\u001B[38;5;241m.\u001B[39minit_metric()\n\u001B[0;32m--> 427\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m s, (batch_y, batch_x) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalid_loader)):\n\u001B[1;32m    428\u001B[0m     loss, pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep(batch_y\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), batch_x, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mevaluate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    429\u001B[0m     all_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:444\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:390\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1075\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1068\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1069\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1073\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1074\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1075\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1077\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/context.py:284\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinel \u001B[38;5;241m=\u001B[39m parent_r\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(parent_w, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m, closefd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 62\u001B[0m         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetbuffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     fds_to_close \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainer.train()\n",
    "    trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}