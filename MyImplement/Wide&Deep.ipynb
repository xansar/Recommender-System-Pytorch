{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wide&Deep"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 加载依赖\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.criteo_dataset import CriteoDataset\n",
    "from utils.metric import CTRMetric\n",
    "from utils.trainer import Trainer\n",
    "from utils.utils import weight_init"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 使用的超参数\n",
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read('./config/wide&deep.ini', encoding='utf-8')\n",
    "config = config._sections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(config['DATA']['num_workers'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    }
   ],
   "source": [
    "# 使用的数据集为Criteo数据集\n",
    "train_pth = '../dataset/criteo-100k-train.txt'\n",
    "valid_pth = '../dataset/criteo-100k-valid.txt'\n",
    "test_pth = '../dataset/criteo-100k-test.txt'\n",
    "train_set = CriteoDataset(train_pth, mode='train')\n",
    "valid_set = CriteoDataset(valid_pth, mode='valid', encoders=train_set.encoders)\n",
    "test_set = CriteoDataset(valid_pth, mode='test', encoders=train_set.encoders)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=eval(config['DATA']['train_batch_size']),\n",
    "    shuffle=True,\n",
    "    num_workers=eval(config['DATA']['num_workers']),\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_set,\n",
    "    batch_size=eval(config['DATA']['valid_batch_size']),\n",
    "    shuffle=False,\n",
    "    num_workers=eval(config['DATA']['num_workers']),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=eval(config['DATA']['test_batch_size']),\n",
    "    shuffle=False,\n",
    "    num_workers=eval(config['DATA']['num_workers']),\n",
    ")\n",
    "\n",
    "# for e in range(2):\n",
    "#     for step, (batch_y, batch_X) in enumerate(tqdm(train_loader)):\n",
    "#         print(f'epoch: {e}\\tstep: {step}\\tbatch_X: {batch_X}\\tbatch_y: {batch_y}')\n",
    "#         if step >= 10:\n",
    "#             break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0.]), tensor([[ 3.7698e+00,  2.6380e+03,  1.2000e+01,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  2.0000e+00,  2.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00,  2.9000e+01,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0000e+00, -1.0000e+00,  4.0117e+01,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 9.0000e+00,  1.3700e+02,  1.0000e+01,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00,  0.0000e+00,  7.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])]\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    print(data)\n",
    "    print(data[1][0][:32].shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[512, 256, 128]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(config['MODEL']['feature_dims'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 编写模型，简单起见，把数据集中的连续型特征（包括目标编码后的特征）放到deep里（0：32），剩下（32：111）的放到wide里\n",
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, config:ConfigParser):\n",
    "        self.config = config\n",
    "        super(WideAndDeep, self).__init__()\n",
    "        self.wide_features_num = eval(config['MODEL']['wide_features_num'])\n",
    "        self.deep_features_num = eval(config['MODEL']['deep_features_num'])\n",
    "        self.one_hot_features_num = eval(config['MODEL']['one_hot_features_num'])\n",
    "        self.embed_dim = eval(config['MODEL']['embed_dim'])\n",
    "        self.feature_dims = eval(config['MODEL']['feature_dims'])\n",
    "        self.wide_features_range = eval(config['MODEL']['wide_features_range'])\n",
    "        self.deep_features_range = eval(config['MODEL']['deep_features_range'])\n",
    "\n",
    "        self.wide_bn = nn.BatchNorm1d(self.wide_features_num)\n",
    "        self.wide = nn.Linear(self.wide_features_num, 1)\n",
    "\n",
    "        self.deep_embed = nn.Embedding(num_embeddings=self.deep_features_num, embedding_dim=self.embed_dim)\n",
    "        deep_input_dim = self.one_hot_features_num * self.embed_dim\n",
    "        self.feature_dims.insert(0, deep_input_dim)\n",
    "        self.feature_dims.append(1)\n",
    "\n",
    "        self.deep_bn = nn.BatchNorm1d(deep_input_dim)\n",
    "\n",
    "        self.deep = nn.Sequential()\n",
    "        for i in range(len(self.feature_dims)):\n",
    "            self.deep.add_module(f'linear{i}', nn.Linear(self.feature_dims[i], self.feature_dims[i + 1]))\n",
    "            if i == len(self.feature_dims) - 2:\n",
    "                break\n",
    "            self.deep.add_module(f'relu{i}',nn.LeakyReLU())\n",
    "\n",
    "\n",
    "    def forward(self, batch_x):\n",
    "        bsz = batch_x.size()[0]\n",
    "        # ========wide=======\n",
    "        # bsz, self.wide_features_num\n",
    "        wide_features = batch_x[:, self.wide_features_range[0]: self.wide_features_range[1]]\n",
    "        # print(wide_features.shape)\n",
    "        # bsz, 1\n",
    "        wide_features = self.wide(self.wide_bn(wide_features))\n",
    "\n",
    "\n",
    "        # ========deep=======\n",
    "        # bsz, self.deep_features_num\n",
    "        deep_features = batch_x[:, self.deep_features_range[0]: self.deep_features_range[1]]\n",
    "        # print(deep_features.shape)\n",
    "        # 这里利用了onehot向量组合的特性，每一行1的个数等于原始数据中被onehot处理的特征个数，也等于deep feature行求和的结果\n",
    "        k = int(torch.sum(deep_features[0]).item())\n",
    "        # print(f'k={k}')\n",
    "        _, idx = torch.topk(deep_features, k)\n",
    "        # embed: bsz, self.deep_features_num, self.embed_dim\n",
    "        # after view: bsz, self.deep_features_num * self.embed_dim\n",
    "        deep_features = self.deep_embed(idx).view(bsz, -1)\n",
    "        # print(deep_features.shape)\n",
    "        # bsz, 1\n",
    "\n",
    "        deep_features = self.deep(self.deep_bn(deep_features))\n",
    "        # raise KeyboardInterrupt\n",
    "        return deep_features + wide_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0887])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型和参数\n",
    "model = WideAndDeep(config)\n",
    "print(model.wide.bias.data)\n",
    "model.apply(weight_init)\n",
    "print(model.wide.bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Config==========\n",
      "TRAIN: \n",
      "\tepoch: 30\n",
      "\tdevice: mps\n",
      "OPTIM: \n",
      "\tlearning_rate: 1e-3\n",
      "\tweight_decay: 1e-1\n",
      "LOSS: \n",
      "\tpos_weight: 5.0\n",
      "MODEL: \n",
      "\tembed_dim: 256\n",
      "\tone_hot_features_num: 7\n",
      "\twide_features_num: 32\n",
      "\twide_features_range: [0, 32]\n",
      "\tdeep_features_num: 79\n",
      "\tdeep_features_range: [32, 111]\n",
      "\tfeature_dims: [512, 256, 128]\n",
      "\ttask: classification\n",
      "\tuser_num: 611\n",
      "\titem_num: 193610\n",
      "DATA: \n",
      "\ttrain_batch_size: 256\n",
      "\tvalid_batch_size: 128\n",
      "\ttest_batch_size: 128\n",
      "\tdataset_ratio: [0.8, 0.1, 0.1]\n",
      "\tnum_workers: 2\n",
      "\tnum_feature: 111\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(lr=eval(config['OPTIM']['learning_rate']), params=model.parameters(), weight_decay=eval(config['OPTIM']['weight_decay']))\n",
    "loss_func = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(eval(config['LOSS']['pos_weight'])))\n",
    "metric = CTRMetric()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer,\n",
    "    metric=metric,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    config=config,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========TRAIN BEGIN==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 62.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\n",
      "Loss: 1.2085383024078589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 1\n",
      "loss: 1.277462159531026\n",
      "accuracy: 0.714399\n",
      "precision: 0.414783\n",
      "recall: 0.550818\n",
      "F1: 0.469138\n",
      "AUC: 0.713258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 65.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2\n",
      "Loss: 1.0086587915024436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 2\n",
      "loss: 1.2050770589067965\n",
      "accuracy: 0.748121\n",
      "precision: 0.451978\n",
      "recall: 0.467982\n",
      "F1: 0.456204\n",
      "AUC: 0.727486\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3\n",
      "Loss: 0.9475117238184896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 3\n",
      "loss: 1.1701276196709163\n",
      "accuracy: 0.748912\n",
      "precision: 0.453450\n",
      "recall: 0.465058\n",
      "F1: 0.456236\n",
      "AUC: 0.730480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 62.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4\n",
      "Loss: 0.938360391143031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 29.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 4\n",
      "loss: 1.1564572015895118\n",
      "accuracy: 0.751088\n",
      "precision: 0.457934\n",
      "recall: 0.469742\n",
      "F1: 0.460716\n",
      "AUC: 0.729842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5\n",
      "Loss: 0.949598237538871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 5\n",
      "loss: 1.156926397281357\n",
      "accuracy: 0.739320\n",
      "precision: 0.438072\n",
      "recall: 0.478126\n",
      "F1: 0.454424\n",
      "AUC: 0.723160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 64.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6\n",
      "Loss: 0.9620775784166476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 29.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 6\n",
      "loss: 1.167322069783754\n",
      "accuracy: 0.746835\n",
      "precision: 0.449094\n",
      "recall: 0.445234\n",
      "F1: 0.444014\n",
      "AUC: 0.720431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 64.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7\n",
      "Loss: 0.9683396835296679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 30.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 7\n",
      "loss: 1.1616799771031248\n",
      "accuracy: 0.737441\n",
      "precision: 0.434934\n",
      "recall: 0.472422\n",
      "F1: 0.449897\n",
      "AUC: 0.719739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8\n",
      "Loss: 0.9724025029343919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 8\n",
      "loss: 1.1582144544094424\n",
      "accuracy: 0.733782\n",
      "precision: 0.429514\n",
      "recall: 0.477529\n",
      "F1: 0.449318\n",
      "AUC: 0.720537\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9\n",
      "Loss: 0.9725071376504989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 29.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 9\n",
      "loss: 1.162882379338711\n",
      "accuracy: 0.744660\n",
      "precision: 0.445369\n",
      "recall: 0.447593\n",
      "F1: 0.443468\n",
      "AUC: 0.722220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/xansar/PycharmProjects/RecommenderSystem/Recommender-System-Pytorch/MyImplement/utils/__init__.py\", line 1, in <module>\n",
      "    from . import criteo_dataset, movielens_dataset, metric, trainer\n",
      "  File \"/Users/xansar/PycharmProjects/RecommenderSystem/Recommender-System-Pytorch/MyImplement/utils/criteo_dataset.py\", line 3, in <module>\n",
      "    import pandas_profiling as pp\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/__init__.py\", line 6, in <module>\n",
      "    from pandas_profiling.controller import pandas_decorator\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/controller/pandas_decorator.py\", line 4, in <module>\n",
      "    from pandas_profiling.profile_report import ProfileReport\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/profile_report.py\", line 16, in <module>\n",
      "    from pandas_profiling.model.describe import describe as describe_df\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/model/describe.py\", line 18, in <module>\n",
      "    from pandas_profiling.model.pairwise import get_scatter_plot, get_scatter_tasks\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/model/pairwise.py\", line 6, in <module>\n",
      "    from pandas_profiling.visualisation.plot import scatter_pairwise\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/visualisation/plot.py\", line 8, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/seaborn/__init__.py\", line 2, in <module>\n",
      "    from .rcmod import *  # noqa: F401,F403\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/seaborn/rcmod.py\", line 7, in <module>\n",
      "    from . import palettes\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/seaborn/palettes.py\", line 9, in <module>\n",
      "    from .utils import desaturate, get_color_cycle\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/seaborn/utils.py\", line 10, in <module>\n",
      "    from scipy import stats\n",
      "  File \"<frozen importlib._bootstrap>\", line 1039, in _handle_fromlist\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/__init__.py\", line 211, in __getattr__\n",
      "    return _importlib.import_module(f'scipy.{name}')\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/stats/__init__.py\", line 467, in <module>\n",
      "    from ._stats_py import *\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/stats/_stats_py.py\", line 46, in <module>\n",
      "    from . import distributions\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/stats/distributions.py\", line 8, in <module>\n",
      "    from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen)\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\", line 24, in <module>\n",
      "    from scipy import optimize\n",
      "  File \"<frozen importlib._bootstrap>\", line 1039, in _handle_fromlist\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/__init__.py\", line 211, in __getattr__\n",
      "    return _importlib.import_module(f'scipy.{name}')\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/optimize/__init__.py\", line 401, in <module>\n",
      "    from ._minimize import *\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 26, in <module>\n",
      "    from ._trustregion_constr import _minimize_trustregion_constr\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/scipy/optimize/_trustregion_constr/__init__.py\", line 4, in <module>\n",
      "    from .minimize_trustregion_constr import _minimize_trustregion_constr\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 654, in _load_unlocked\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtest()\n",
      "File \u001B[0;32m~/PycharmProjects/RecommenderSystem/Recommender-System-Pytorch/MyImplement/utils/trainer.py:106\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m    105\u001B[0m     all_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m--> 106\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m s, batch_data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader)):\n\u001B[1;32m    107\u001B[0m         loss, pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep(batch_data, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    108\u001B[0m         all_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:444\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:390\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1075\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1068\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1069\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1073\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1074\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1075\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1077\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/context.py:284\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinel \u001B[38;5;241m=\u001B[39m parent_r\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(parent_w, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m, closefd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 62\u001B[0m         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetbuffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     fds_to_close \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainer.train()\n",
    "    trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}