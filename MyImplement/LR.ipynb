{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 依赖，使用torch构建模型\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import CriteoDataset, CTRMetric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 数据集处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 使用的超参数\n",
    "config = {\n",
    "    'TRAIN_BATCH_SIZE': 128,\n",
    "    'VALID_BATCH_SIZE': 128,\n",
    "    'TEST_BATCH_SIZE': 128,\n",
    "    'DEVICE': 'mps',\n",
    "    'NUM_WORKERS': 6,\n",
    "    'EPOCH': 30,\n",
    "    'NUM_FEATURE': 111,\n",
    "    'POS_WEIGHT': 4,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/category_encoders/target_encoder.py:92: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/category_encoders/target_encoder.py:97: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    }
   ],
   "source": [
    "# 使用的数据集为Criteo数据集\n",
    "train_pth = '../dataset/criteo-100k-train.txt'\n",
    "valid_pth = '../dataset/criteo-100k-valid.txt'\n",
    "test_pth = '../dataset/criteo-100k-test.txt'\n",
    "train_set = CriteoDataset(train_pth, mode='train')\n",
    "valid_set = CriteoDataset(valid_pth, mode='valid', encoders=train_set.encoders)\n",
    "test_set = CriteoDataset(valid_pth, mode='test', encoders=train_set.encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=config['TRAIN_BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['NUM_WORKERS']\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_set,\n",
    "    batch_size=config['VALID_BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['NUM_WORKERS']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=config['TEST_BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['NUM_WORKERS']\n",
    ")\n",
    "\n",
    "# for e in range(2):\n",
    "#     for step, (batch_y, batch_X) in enumerate(tqdm(train_loader)):\n",
    "#         print(f'epoch: {e}\\tstep: {step}\\tbatch_X: {batch_X}\\tbatch_y: {batch_y}')\n",
    "#         if step >= 10:\n",
    "#             break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features=num_features)\n",
    "        self.linar_layer = nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self, batch_X):\n",
    "        return self.linar_layer(self.bn(batch_X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 构建trianer\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss_func, optimizer, metric, train_loader, valid_loader, test_loader, config):\n",
    "        self.config = config\n",
    "        print('='*10 + \"Config\" + '='*10)\n",
    "        for k, v in self.config.items():\n",
    "            print(f'{k}: {v}')\n",
    "        print('='*25)\n",
    "        self.model: nn.Module = model\n",
    "        self.loss_func: nn.Module = loss_func\n",
    "        self.optimizer: optim.Optimizer = optimizer\n",
    "        self.metric = metric\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "        self.to(self.config['DEVICE'])\n",
    "\n",
    "    def to(self, device=None):\n",
    "        if device is None:\n",
    "            self.model = self.model.to(self.config['DEVICE'])\n",
    "            self.loss_func = self.loss_func.to(self.config['DEVICE'])\n",
    "        else:\n",
    "            self.model = self.model.to(device)\n",
    "            self.loss_func = self.loss_func.to(self.config['DEVICE'])\n",
    "            self.config['DEVICE'] = device\n",
    "\n",
    "    def step(self, batch_y, batch_x, mode='train'):\n",
    "        device = self.config['DEVICE']\n",
    "        if mode == 'train':\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            batch_y = batch_y.to(device)\n",
    "            batch_x = batch_x.to(device)\n",
    "\n",
    "            pred = self.model(batch_x)\n",
    "            loss = self.loss_func(pred, batch_y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            return loss.item(), pred\n",
    "        elif mode == 'evaluate':\n",
    "            with torch.no_grad():\n",
    "                self.model.eval()\n",
    "\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_x = batch_x.to(device)\n",
    "\n",
    "                pred = self.model(batch_x)\n",
    "                loss = self.loss_func(pred, batch_y)\n",
    "                return loss.item(), pred\n",
    "        else:\n",
    "            raise ValueError(\"Wrong Mode\")\n",
    "    def _compute_metric(self, metric_str):\n",
    "        self.metric.get_batch_metric()\n",
    "        for k, v in self.metric.metric_dict.items():\n",
    "            if k == 'cnt':\n",
    "                continue\n",
    "            metric_str += f'{k}: {v:4f}\\n'\n",
    "        self.metric.init_metric()\n",
    "        return metric_str\n",
    "    def train(self):\n",
    "        print(\"=\"*10 + \"TRAIN BEGIN\" + \"=\"*10)\n",
    "        epoch = self.config['EPOCH']\n",
    "        for e in range(1, epoch + 1):\n",
    "            all_loss = 0.0\n",
    "            for s, (batch_y, batch_x) in enumerate(tqdm(train_loader)):\n",
    "                loss, pred = self.step(batch_y.unsqueeze(1), batch_x, mode='train')\n",
    "                all_loss += loss\n",
    "\n",
    "            all_loss /= s + 1\n",
    "            print(f'Train Epoch: {e}\\nLoss: {all_loss}')\n",
    "            if e % 1 == 0:\n",
    "                all_loss = 0.0\n",
    "                self.metric.init_metric()\n",
    "                for s, (batch_y, batch_x) in enumerate(tqdm(valid_loader)):\n",
    "                    loss, pred = self.step(batch_y.unsqueeze(1), batch_x, mode='evaluate')\n",
    "                    all_loss += loss\n",
    "\n",
    "                    self.metric.compute_metric(pred, batch_y)\n",
    "                all_loss /= s + 1\n",
    "                metric_str = f'loss: {all_loss}\\n'\n",
    "                metric_str = self._compute_metric(metric_str)\n",
    "                print(f'Valid Epoch: {e}\\n' + metric_str)\n",
    "        print(\"=\"*10 + \"TRAIN END\" + \"=\"*10)\n",
    "\n",
    "    def test(self):\n",
    "        all_loss = 0.0\n",
    "        self.metric.init_metric()\n",
    "        for s, (batch_y, batch_x) in enumerate(tqdm(test_loader)):\n",
    "            loss, pred = self.step(batch_y.unsqueeze(1), batch_x, mode='evaluate')\n",
    "            all_loss += loss\n",
    "\n",
    "        all_loss /= s + 1\n",
    "        metric_str = f'loss: {all_loss}\\n'\n",
    "        metric_str = self._compute_metric(metric_str)\n",
    "        print(f'Test Loss: {all_loss}\\n' + metric_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Config==========\n",
      "TRAIN_BATCH_SIZE: 128\n",
      "VALID_BATCH_SIZE: 128\n",
      "TEST_BATCH_SIZE: 128\n",
      "DEVICE: mps\n",
      "NUM_WORKERS: 6\n",
      "EPOCH: 30\n",
      "NUM_FEATURE: 111\n",
      "POS_WEIGHT: [4]\n",
      "LEARNING_RATE: 0.0001\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegressionModel(num_features=config['NUM_FEATURE'])\n",
    "weight = torch.tensor(config['POS_WEIGHT'])\n",
    "loss_func = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = optim.Adam(lr=config['LEARNING_RATE'], params=model.parameters())\n",
    "metric = CTRMetric()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer,\n",
    "    metric=metric,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    config=config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========TRAIN BEGIN==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 67.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\n",
      "Loss: 1.0577327836036683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 1\n",
      "loss: 1.0555117107644867\n",
      "accuracy: 0.737342\n",
      "precision: 0.429355\n",
      "recall: 0.428049\n",
      "F1: 0.424967\n",
      "AUC: 0.710751\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 68.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2\n",
      "Loss: 0.9186187308311462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 2\n",
      "loss: 1.0296182790889015\n",
      "accuracy: 0.738924\n",
      "precision: 0.440759\n",
      "recall: 0.506901\n",
      "F1: 0.468177\n",
      "AUC: 0.736729\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:09<00:00, 68.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3\n",
      "Loss: 0.866689479637146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 3\n",
      "loss: 1.012877725347688\n",
      "accuracy: 0.737144\n",
      "precision: 0.439886\n",
      "recall: 0.537942\n",
      "F1: 0.480869\n",
      "AUC: 0.746732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4\n",
      "Loss: 0.8407413570404053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 4\n",
      "loss: 1.0091328809532938\n",
      "accuracy: 0.739122\n",
      "precision: 0.443644\n",
      "recall: 0.543889\n",
      "F1: 0.485548\n",
      "AUC: 0.749602\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 71.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5\n",
      "Loss: 0.8233562371253967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 5\n",
      "loss: 1.0172273063961463\n",
      "accuracy: 0.743968\n",
      "precision: 0.449669\n",
      "recall: 0.528974\n",
      "F1: 0.483197\n",
      "AUC: 0.750255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 71.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6\n",
      "Loss: 0.8124627101898193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 6\n",
      "loss: 1.0250733879548084\n",
      "accuracy: 0.749901\n",
      "precision: 0.458684\n",
      "recall: 0.516927\n",
      "F1: 0.483254\n",
      "AUC: 0.749421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7\n",
      "Loss: 0.8038832220077514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 7\n",
      "loss: 1.0275592494614516\n",
      "accuracy: 0.745154\n",
      "precision: 0.451820\n",
      "recall: 0.534962\n",
      "F1: 0.486703\n",
      "AUC: 0.748990\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8\n",
      "Loss: 0.7969004862785339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 8\n",
      "loss: 1.0252509833891181\n",
      "accuracy: 0.750297\n",
      "precision: 0.459529\n",
      "recall: 0.517545\n",
      "F1: 0.483591\n",
      "AUC: 0.749141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 71.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9\n",
      "Loss: 0.7916098605155945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 9\n",
      "loss: 1.0363187269319463\n",
      "accuracy: 0.746440\n",
      "precision: 0.453645\n",
      "recall: 0.530120\n",
      "F1: 0.485554\n",
      "AUC: 0.746968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 71.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10\n",
      "Loss: 0.7872112084388733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 10\n",
      "loss: 1.038079438330252\n",
      "accuracy: 0.752176\n",
      "precision: 0.461570\n",
      "recall: 0.515112\n",
      "F1: 0.483594\n",
      "AUC: 0.749421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 71.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11\n",
      "Loss: 0.7843875405311584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 11\n",
      "loss: 1.0421081600309927\n",
      "accuracy: 0.752373\n",
      "precision: 0.462973\n",
      "recall: 0.504397\n",
      "F1: 0.479516\n",
      "AUC: 0.747742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 69.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12\n",
      "Loss: 0.7821734395980835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 12\n",
      "loss: 1.0572454868992673\n",
      "accuracy: 0.747132\n",
      "precision: 0.453794\n",
      "recall: 0.513601\n",
      "F1: 0.478608\n",
      "AUC: 0.746095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 69.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13\n",
      "Loss: 0.7817610609054565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 13\n",
      "loss: 1.0468581492387796\n",
      "accuracy: 0.754450\n",
      "precision: 0.466657\n",
      "recall: 0.496185\n",
      "F1: 0.477626\n",
      "AUC: 0.748067\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14\n",
      "Loss: 0.7790017313957215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 14\n",
      "loss: 1.0554074577138395\n",
      "accuracy: 0.751483\n",
      "precision: 0.461252\n",
      "recall: 0.502280\n",
      "F1: 0.477563\n",
      "AUC: 0.747561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15\n",
      "Loss: 0.7783238967895508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 15\n",
      "loss: 1.0596637891817697\n",
      "accuracy: 0.747627\n",
      "precision: 0.452311\n",
      "recall: 0.506893\n",
      "F1: 0.474969\n",
      "AUC: 0.744651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 69.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16\n",
      "Loss: 0.7768620523452758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 16\n",
      "loss: 1.0657930962647064\n",
      "accuracy: 0.759889\n",
      "precision: 0.472401\n",
      "recall: 0.467350\n",
      "F1: 0.466899\n",
      "AUC: 0.745698\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 69.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17\n",
      "Loss: 0.777294733428955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:07<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 17\n",
      "loss: 1.057172275042232\n",
      "accuracy: 0.748418\n",
      "precision: 0.454095\n",
      "recall: 0.506926\n",
      "F1: 0.475441\n",
      "AUC: 0.746172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 69.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18\n",
      "Loss: 0.7768491014480591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 18\n",
      "loss: 1.0593930060350443\n",
      "accuracy: 0.753362\n",
      "precision: 0.461143\n",
      "recall: 0.489052\n",
      "F1: 0.471610\n",
      "AUC: 0.746387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19\n",
      "Loss: 0.7746786587715149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 19\n",
      "loss: 1.0596915762635726\n",
      "accuracy: 0.758604\n",
      "precision: 0.471331\n",
      "recall: 0.480927\n",
      "F1: 0.472825\n",
      "AUC: 0.747887\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20\n",
      "Loss: 0.7741651511192322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 20\n",
      "loss: 1.0574604280387299\n",
      "accuracy: 0.748022\n",
      "precision: 0.453297\n",
      "recall: 0.510963\n",
      "F1: 0.476885\n",
      "AUC: 0.745680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21\n",
      "Loss: 0.7739366086006164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 21\n",
      "loss: 1.0641404322431058\n",
      "accuracy: 0.748912\n",
      "precision: 0.452502\n",
      "recall: 0.491283\n",
      "F1: 0.467891\n",
      "AUC: 0.743575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22\n",
      "Loss: 0.7727512150764465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Epoch: 22\n",
      "loss: 1.0627609619611427\n",
      "accuracy: 0.750297\n",
      "precision: 0.455396\n",
      "recall: 0.492948\n",
      "F1: 0.470192\n",
      "AUC: 0.744255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 70.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23\n",
      "Loss: 0.7746822437286377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:03<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/xansar/PycharmProjects/RecommenderSystem/Recommender-System-Pytorch/MyImplement/utils/utils.py\", line 3, in <module>\n",
      "    import pandas_profiling as pp\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/__init__.py\", line 6, in <module>\n",
      "    from pandas_profiling.controller import pandas_decorator\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/controller/pandas_decorator.py\", line 4, in <module>\n",
      "    from pandas_profiling.profile_report import ProfileReport\n",
      "  File \"/Users/xansar/.conda/envs/Recom\n",
      "menderSystem/lib/python3.8/site-packages/pandas_profiling/profile_report.py\", line 14, in <module>\n",
      "    from pandas_profiling.expectations_report import ExpectationsReport\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/expectations_report.py\", line 9, in <module>\n",
      "    from pandas_profiling.utils.dataframe import slugify\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/pandas_profiling/utils/dataframe.py\", line 8, in <module>\n",
      "    import joblib\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/__init__.py\", line 113, in <module>\n",
      "    from .memory import Memory, MemorizedResult, register_store_backend\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/memory.py\", line 32, in <module>\n",
      "    from ._store_backends import StoreBackendBase, FileSystemStoreBackend\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/_store_backends.py\", line 15, in <module>\n",
      "    from .backports import concurrency_safe_rename\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/joblib/backports.py\", line 7, in <module>\n",
      "    from distutils.version import LooseVersion\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/_distutils_hack/__init__.py\", line 90, in find_spec\n",
      "    return method()\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/_distutils_hack/__init__.py\", line 101, in spec_for_distutils\n",
      "    mod = importlib.import_module('setuptools._distutils')\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/setuptools/__init__.py\", line 18, in <module>\n",
      "    from setuptools.dist import Distribution\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/setuptools/dist.py\", line 48, in <module>\n",
      "    from . import _reqs\n",
      "  File \"/Users/xansar/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/setuptools/_reqs.py\", line 1, in <module>\n",
      "    import setuptools.extern.jaraco.text as text\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1407, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1379, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1522, in find_spec\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtest()\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     74\u001B[0m all_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric\u001B[38;5;241m.\u001B[39minit_metric()\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m s, (batch_y, batch_x) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(valid_loader)):\n\u001B[1;32m     77\u001B[0m     loss, pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep(batch_y\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), batch_x, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mevaluate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     78\u001B[0m     all_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:444\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:390\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1075\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1068\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1069\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1073\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1074\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1075\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1077\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/context.py:284\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/RecommenderSystem/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinel \u001B[38;5;241m=\u001B[39m parent_r\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(parent_w, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m, closefd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 62\u001B[0m         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetbuffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     fds_to_close \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainer.train()\n",
    "    trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}